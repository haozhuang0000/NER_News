{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "from typing import Any, Dict, List, Optional\n",
    "from bson.binary import Binary\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database(DBS):\n",
    "    client = MongoClient('mongodb://crinlp:123@10.230.252.3:27017/?authSource=admin&readPreference=primary&appname=MongoDB%20Compass&ssl=false')\n",
    "    db = client[DBS]\n",
    "    return db\n",
    "\n",
    "db = get_database('preprocessing_texts')\n",
    "col_ner = db['NER_Mapping_testFM']\n",
    "col_data = db['v5_meta_examineresult']\n",
    "col_store_false_ss = db['selected_sentences_v5_FalseMapping']\n",
    "col_store_false_nm = db['NER_Mapping_FalseMapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifyFalseMapping():\n",
    "\n",
    "    def __init__(self, col_ner, col_data, col_store_false_ss, col_store_false_nm) -> None:\n",
    "        self.col_ner = col_ner\n",
    "        self.col_data = col_data\n",
    "        self.col_store_false_ss = col_store_false_ss\n",
    "        self.col_store_false_nm = col_store_false_nm\n",
    "\n",
    "\n",
    "    def extract_ner_data(self, u3_id_list: List[int]) -> List[dict]:\n",
    "        \"\"\"\n",
    "        input empty list means take all updated == 1\n",
    "        \"\"\"\n",
    "        if u3_id_list == []:\n",
    "            ner_data = col_ner.find({'Updated':1})\n",
    "        else:\n",
    "            ner_data = col_ner.find({'Updated':1, 'U3_Company_Number': {\"$in\": u3_id_list}})\n",
    "        ner_data_list = []\n",
    "        for i in ner_data:\n",
    "            ner_data_list.append(i)\n",
    "        return ner_data_list\n",
    "    \n",
    "    def convert_uuid(self, x: str) -> str:\n",
    "        id = uuid.UUID(x)\n",
    "        return id\n",
    "    \n",
    "    def modify_data(self, data_in: dict, ner_data: dict, entity_index: List[int]) -> dict:\n",
    "        common_name = ['Similarity', 'Similarity_1st', 'Similarity_2nd', '1st_cleaned_ner_entity', \n",
    "        '1st_matched_cleaned_comp', '2nd_ner_entity', '2nd_matched_comp']\n",
    "        name_in_ss = ['Entity_id', 'Bingo_entity'] + common_name\n",
    "        name_in_ner_mapping = ['U3_Company_Number', 'Company_Name'] + common_name\n",
    "        len_name = len(name_in_ss)\n",
    "        outdata = {name: [] for name in name_in_ss}\n",
    "        for idx in range(len_name):\n",
    "            list_data = data_in[name_in_ss[idx]]\n",
    "            list_ner = ner_data[name_in_ner_mapping[idx]] ## Constant\n",
    "            for data_i in range(len(list_data)):\n",
    "                if data_i in entity_index:\n",
    "                    outdata[name_in_ss[idx]].append(list_ner)\n",
    "                else:\n",
    "                    outdata[name_in_ss[idx]].append(list_data[data_i])\n",
    "        return outdata\n",
    "    \n",
    "    def modified_ner_mapping(self, ner_name_list: List[str], ner_correction_list: List[List]) -> None:\n",
    "        len_name = len(ner_name_list)\n",
    "        for ner_name_index in range(len_name):\n",
    "            find_cursor = self.col_ner.find({'NER_Name': ner_name_list[ner_name_index]})\n",
    "            ner_data = [i for i in find_cursor][0]\n",
    "            print(ner_data)\n",
    "            try:\n",
    "                self.col_store_false_nm.insert_one(ner_data)\n",
    "            except:\n",
    "                pass\n",
    "            self.col_ner.delete_one({\"_id\": ner_data['_id']})\n",
    "            results_dict = {\"_id\": ner_data['_id'], \n",
    "                \"U3_Company_Number\": ner_correction_list[ner_name_index][0], \"Company_Name\": ner_correction_list[ner_name_index][1],\n",
    "                \"NER_Name\": ner_data[\"NER_Name\"], \"NER_Original_Name\": ner_data[\"NER_Original_Name\"],\n",
    "                \"Similarity\": 1, \"Similarity_1st\": [1], \n",
    "                \"Similarity_2nd\": [1], \"1st_cleaned_ner_entity\": ner_data[\"1st_cleaned_ner_entity\"],\n",
    "                \"1st_matched_cleaned_comp\": ner_data[\"1st_matched_cleaned_comp\"], \"2nd_ner_entity\": ner_data[\"2nd_ner_entity\"], \n",
    "                \"2nd_matched_comp\": ner_data[\"2nd_matched_comp\"], \"Pre_Defined\": 0,\n",
    "                \"Updated\": 1}\n",
    "            self.col_ner.insert_one(results_dict)\n",
    "            break\n",
    "    def run(self):\n",
    "\n",
    "        ner_data_list = self.extract_ner_data([])\n",
    "        for ner_data in ner_data_list:\n",
    "            for ss_data in col_data.find({'NER_Mapping_ID': ner_data['_id']}):\n",
    "                try:\n",
    "                    self.col_store_false_ss.insert_one(ss_data)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                entities = ss_data['Companies_econs_sectors_instruments']\n",
    "                ner_mapping_id = ss_data['NER_Mapping_ID']\n",
    "                store_idx = []\n",
    "\n",
    "                ## Look for index that need to be modified\n",
    "                for entity_i in range(len(entities)):\n",
    "                    if entities[entity_i] == ner_data['NER_Name'] and ner_mapping_id[entity_i] == ner_data['_id']:\n",
    "                        store_idx.append(entity_i)\n",
    "                \n",
    "                modified_dict = self.modify_data(ss_data, ner_data, store_idx)\n",
    "                results_dict = {\"_id\": ss_data['_id'], \"Sentence_id\": ss_data['Sentence_id'], \"Output_sentence1\": ss_data['Output_sentence1'], \n",
    "                                \"Output_sentence2\": ss_data['Output_sentence2'], \"Storage_date\": ss_data['Storage_date'], \"Companies_econs_sectors_instruments\": ss_data['Companies_econs_sectors_instruments'],\n",
    "                                \"Source\": ss_data['Source'], \"Category\": ss_data['Category'], \"Date\": ss_data['Date'], \n",
    "                                \"Title\": ss_data['Title'], \"Link\": ss_data['Link'], \n",
    "                                \"Entity_id\": modified_dict[\"Entity_id\"], \"Bingo_entity\": modified_dict[\"Bingo_entity\"],\n",
    "                                \"Similarity\": modified_dict[\"Similarity\"], \"Similarity_1st\": modified_dict[\"Similarity_1st\"], \n",
    "                                \"Similarity_2nd\": modified_dict[\"Similarity_2nd\"], \"1st_cleaned_ner_entity\": modified_dict[\"1st_cleaned_ner_entity\"],\n",
    "                                \"1st_matched_cleaned_comp\": modified_dict[\"1st_matched_cleaned_comp\"], \"2nd_ner_entity\": modified_dict[\"2nd_ner_entity\"], \n",
    "                                \"2nd_matched_comp\": modified_dict[\"2nd_matched_comp\"], \"NER_Mapping_ID\": ss_data['NER_Mapping_ID'],\n",
    "                                \"Updated\": 1}\n",
    "                ## Delete previous one\n",
    "                self.col_data.delete_one({'_id': ss_data['_id']})\n",
    "                self.col_data.insert_one(results_dict)\n",
    "\n",
    "\n",
    "\n",
    "# for ner_data in ner_data_list:\n",
    "#     for ss_data in col_data.find({'NER_Mapping_ID': ner_data['_id']}):\n",
    "#         try:\n",
    "#             col_store_temp_data.insert_one(ss_data)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         entities = ss_data['Companies_econs_sectors_instruments']\n",
    "#         ner_mapping_id = ss_data['NER_Mapping_ID']\n",
    "#         store_idx = []\n",
    "\n",
    "#         ## Look for index that need to be modified\n",
    "#         for entity_i in range(len(entities)):\n",
    "#             if entities[entity_i] == ner_data['NER_Name'] and ner_mapping_id[entity_i] == ner_data['_id']:\n",
    "#                 store_idx.append(entity_i)\n",
    "        \n",
    "#         modified_dict = modify_data(ss_data, ner_data, store_idx)\n",
    "#         results_dict = {\"_id\": ss_data['_id'], \"Sentence_id\": ss_data['Sentence_id'], \"Output_sentence1\": ss_data['Output_sentence1'], \n",
    "#                         \"Output_sentence2\": ss_data['Output_sentence2'], \"Storage_date\": ss_data['Storage_date'], \"Companies_econs_sectors_instruments\": ss_data['Companies_econs_sectors_instruments'],\n",
    "#                         \"Source\": ss_data['Source'], \"Category\": ss_data['Category'], \"Date\": ss_data['Date'], \n",
    "#                         \"Title\": ss_data['Title'], \"Link\": ss_data['Link'], \n",
    "#                         \"Entity_id\": modified_dict[\"Entity_id\"], \"Bingo_entity\": modified_dict[\"Bingo_entity\"],\n",
    "#                         \"Similarity\": modified_dict[\"Similarity\"], \"Similarity_1st\": modified_dict[\"Similarity_1st\"], \n",
    "#                         \"Similarity_2nd\": modified_dict[\"Similarity_2nd\"], \"1st_cleaned_ner_entity\": modified_dict[\"1st_cleaned_ner_entity\"],\n",
    "#                         \"1st_matched_cleaned_comp\": modified_dict[\"1st_matched_cleaned_comp\"], \"2nd_ner_entity\": modified_dict[\"2nd_ner_entity\"], \n",
    "#                         \"2nd_matched_comp\": modified_dict[\"2nd_matched_comp\"], \"NER_Mapping_ID\": ss_data['NER_Mapping_ID'],\n",
    "#                         \"Updated\": 1}\n",
    "#         ## Delete previous one\n",
    "#         col_data.delete_one({'_id': ss_data['_id']})\n",
    "#         col_data.insert_one(results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfalsemapping = ModifyFalseMapping(col_ner, col_data, col_store_false_ss, col_store_false_nm)\n",
    "mfalsemapping.modified_ner_mapping([\"Facebook\"], [[129360, \"Meta Platforms Inc\"]])\n",
    "mfalsemapping.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binary(b'\\xbd\\xeb\\xb8/R2>9\\xab9\\xe7\\x18%=\\x1b\\x0c', 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data_list[0]['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER_NEWS_Github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
